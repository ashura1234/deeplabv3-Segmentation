{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "pascal.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashura1234/deeplabv3-Segmentation/blob/main/pascal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnfB7Go-q3Bi",
        "outputId": "ca57e00a-1b0d-4721-9244-53f371114597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from google.colab import drive\n",
        "\n",
        "import torch.utils.data as data\n",
        "import os\n",
        "from PIL import Image\n",
        "from utils import preprocess"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Pytorch Projects/Image Segmentation/Deeplabv3\n",
            "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n",
            "importing Jupyter notebook from utils.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u5XXAZMq3Bm"
      },
      "source": [
        "class VOCSegmentation(data.Dataset):\n",
        "        \n",
        "    CLASSES = [\n",
        "      'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
        "      'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
        "      'motorbike', 'person', 'potted-plant', 'sheep', 'sofa', 'train',\n",
        "      'tv/monitor'\n",
        "    ]\n",
        "\n",
        "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False, crop_size=None):\n",
        "        self.root = root\n",
        "        _voc_root = os.path.join(self.root, 'VOC2012')\n",
        "        _list_dir = os.path.join(_voc_root, 'list')\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.train = train\n",
        "        self.crop_size = crop_size\n",
        "\n",
        "    \n",
        "        \n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if self.train:\n",
        "            _list_f = os.path.join(_list_dir, 'train_aug.txt')\n",
        "        else:\n",
        "            _list_f = os.path.join(_list_dir, 'val.txt')\n",
        "        self.images = []\n",
        "        self.masks = []\n",
        "        #print(_voc_root)\n",
        "        with open(_list_f, 'r') as lines:\n",
        "            for line in lines:\n",
        "                _image = _voc_root + line.split()[0]\n",
        "                _mask = _voc_root + line.split()[1]\n",
        "                #print(_image)\n",
        "                #print(_mask)\n",
        "                #assert os.path.isfile(_image)\n",
        "                #assert os.path.isfile(_mask)\n",
        "                self.images.append(_image)\n",
        "                self.masks.append(_mask)\n",
        "        print(\"Read\", len(self.images), \"images\")\n",
        "        print(\"Read\", len(self.masks), \"masks\")\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        _img = Image.open(self.images[index]).convert('RGB')\n",
        "        _target = Image.open(self.masks[index])\n",
        "\n",
        "        _img, _target = preprocess(_img, _target,\n",
        "                                   flip=True if self.train else False,\n",
        "                                   scale=(0.5, 2.0) if self.train else None,\n",
        "                                   crop=(self.crop_size, self.crop_size))\n",
        "\n",
        "        if self.transform is not None:\n",
        "            _img = self.transform(_img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            _target = self.target_transform(_target)\n",
        "\n",
        "        return _img, _target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def download(self):\n",
        "        raise NotImplementedError('Automatic download not yet implemented.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb5uy_6Zq3Bp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}